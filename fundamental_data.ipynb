{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamental Data Extraction\n",
    "***\n",
    "Because with Alpha Vantage we don't have access to the complete history of fundamental data of Microsoft, in this notebook I develop code to extract the data directly from Microsoft's investor relations page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# LIBRARIES\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Basic libraries\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualization tools\n",
    "import plotly.io as pio\n",
    "\n",
    "# Personal libraries/modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import data_processing as dp\n",
    "import plotting_tools as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries configurations\n",
    "custom_template = pt.generate_plotly_transparent_template(\n",
    "    color_sequence=pt.CYBERPUNK_COLOR_SEQUENCE,\n",
    "    title_font_color=pt.FONT_COLOR,\n",
    "    axis_font_color=pt.FONT_COLOR,\n",
    "    axis_tick_color=pt.FONT_COLOR,\n",
    "    axis_grid_color=pt.AXIS_COLOR,\n",
    "    legend_font_color=pt.FONT_COLOR,\n",
    "    plot_width=pt.WIDTH,\n",
    "    plot_height=pt.HEIGHT\n",
    ")\n",
    "pio.templates.default = custom_template\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Filter out future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564a464ae96a42f190cd73ab817c5344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# table lists to store quarterly data\n",
    "is_df_list = []\n",
    "bs_df_list = []\n",
    "cf_df_list = []\n",
    "\n",
    "# Year quarter tuples\n",
    "year_quarter_list = [\n",
    "    (year, quarter) for year in range(2009, 2025) for quarter in range(1, 5)\n",
    "]\n",
    "\n",
    "# Cycle through years and quarters\n",
    "for (year, quarter) in tqdm(year_quarter_list):\n",
    "\n",
    "    # Skip 2009 to Q3: before the data comes in a different format\n",
    "    if year == 2009 and quarter < 3:\n",
    "        continue\n",
    "    \n",
    "    # Generate the extraction URL\n",
    "    is_url = f'https://www.microsoft.com/en-us/Investor/earnings/FY-{year}-Q{quarter}/income-statements'\n",
    "    bs_url = f'https://www.microsoft.com/en-us/Investor/earnings/FY-{year}-Q{quarter}/balance-sheets'\n",
    "    cf_url = f'https://www.microsoft.com/en-us/Investor/earnings/FY-{year}-Q{quarter}/cash-flows'\n",
    "    \n",
    "    # Determine the amount of columns selected\n",
    "    if year <= 2010 and quarter <= 3:\n",
    "        cols = [0, 2, 3]\n",
    "    else:\n",
    "        cols = [0, 2]\n",
    "        \n",
    "    # Income Statements table\n",
    "    # -----------------------\n",
    "\n",
    "    # Load table as data frame\n",
    "    is_df = pd.read_html(is_url)[0]\n",
    "\n",
    "    # Clean account description column\n",
    "    account_name = is_df.columns[0]\n",
    "    is_df[account_name] = (\n",
    "        is_df.iloc[:, 0].apply(dp.clean_account) + '_' +\n",
    "        is_df.iloc[:, 1].apply(dp.clean_account)\n",
    "    )\n",
    "\n",
    "    # Select current period\n",
    "    is_df = is_df.iloc[:, cols]\n",
    "\n",
    "    # Parse period date\n",
    "    col_names = [\n",
    "        dp.tuple_to_datetime(t) if i > 0 else 'account' \n",
    "        for i, t in enumerate(is_df.columns)\n",
    "        \n",
    "    ]\n",
    "\n",
    "    # Give columns correct names\n",
    "    is_df.columns = col_names\n",
    "    value_cols = col_names[1:]\n",
    "\n",
    "    # Parse numeric data\n",
    "    is_df[value_cols] = is_df[value_cols].apply(dp.clean_values_series)\n",
    "\n",
    "    # Parse account data\n",
    "    is_df['account'] = is_df['account'].str.replace('us-gaap:', '')\n",
    "\n",
    "    # Drop empty value rows\n",
    "    is_df = is_df.dropna(axis=0, subset=value_cols)\n",
    "\n",
    "    # Save results\n",
    "    is_df_list.append(is_df.set_index('account').T)\n",
    "\n",
    "\n",
    "    # Balance Sheets table\n",
    "    # --------------------\n",
    "\n",
    "    # Load table as data frame\n",
    "    bs_df = pd.read_html(bs_url)[0]\n",
    "\n",
    "    # Clean account description column\n",
    "    account_name = bs_df.columns[0]\n",
    "    bs_df[account_name] = (\n",
    "        bs_df.iloc[:, 0].apply(dp.clean_account) + '_' +\n",
    "        bs_df.iloc[:, 1].apply(dp.clean_account)\n",
    "    )\n",
    "\n",
    "    # Select current period\n",
    "    bs_df = bs_df.iloc[:, cols]\n",
    "\n",
    "    # Parse period date\n",
    "    try:\n",
    "        col_names = [\n",
    "            datetime.strptime(\n",
    "                t[1].split(' (')[0].replace(' ', ''), '%B%d,%Y'\n",
    "            ) \n",
    "            if i > 0 else 'account' for i, t in enumerate(bs_df.columns)\n",
    "        ]\n",
    "    except:\n",
    "        col_names = [\n",
    "            datetime.strptime(\n",
    "                ' '.join(t).replace(' ', ''), '%B%d,%Y'\n",
    "            ) \n",
    "            if i > 0 else 'account' for i, t in enumerate(bs_df.columns)\n",
    "        ]\n",
    "\n",
    "\n",
    "    # Give columns correct names\n",
    "    bs_df.columns = col_names\n",
    "    value_cols = col_names[1:]\n",
    "\n",
    "    # Parse numeric data\n",
    "    bs_df[value_cols] = bs_df[value_cols].apply(dp.clean_values_series)\n",
    "\n",
    "        # Parse account data\n",
    "    bs_df['account'] = bs_df['account'].str.replace('us-gaap:', '')\n",
    "    # Drop empty value rows\n",
    "    bs_df = bs_df.dropna(axis=0, subset=value_cols)\n",
    "\n",
    "    # Save results\n",
    "    bs_df_list.append(bs_df.set_index('account').T)\n",
    "\n",
    "\n",
    "    # Cash Flows Statements table\n",
    "    # ---------------------------\n",
    "\n",
    "    # Load table as data frame\n",
    "    cf_df = pd.read_html(cf_url)[0]\n",
    "\n",
    "    # Clean account description column\n",
    "    account_name = cf_df.columns[0]\n",
    "    cf_df[account_name] = (\n",
    "        cf_df.iloc[:, 0].apply(dp.clean_account) + '_' +\n",
    "        cf_df.iloc[:, 1].apply(dp.clean_account)\n",
    "    )\n",
    "\n",
    "    # Select current period\n",
    "    cf_df = cf_df.iloc[:, cols]\n",
    "\n",
    "    # Parse period date\n",
    "    col_names = [\n",
    "        dp.tuple_to_datetime(t) if i > 0 else 'account' \n",
    "        for i, t in enumerate(cf_df.columns)\n",
    "        \n",
    "    ]\n",
    "\n",
    "    # Give columns correct names\n",
    "    cf_df.columns = col_names\n",
    "    value_cols = col_names[1:]\n",
    "\n",
    "    # Parse numeric data\n",
    "    cf_df[value_cols] = cf_df[value_cols].apply(dp.clean_values_series)\n",
    "\n",
    "        # Parse account data\n",
    "    cf_df['account'] = cf_df['account'].str.replace('us-gaap:', '')\n",
    "    # Drop empty value rows\n",
    "    cf_df = cf_df.dropna(axis=0, subset=value_cols)\n",
    "\n",
    "    # Save results\n",
    "    cf_df_list.append(cf_df.set_index('account').T)\n",
    "\n",
    "    # Break if last period reached\n",
    "    if year == 2024 and quarter == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# CONSOLIDATE ALL FUNDAMENTAL DATA\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Income statements\n",
    "total_is_df = pd.concat(is_df_list).sort_index().reset_index()\n",
    "total_is_df = (\n",
    "    total_is_df\n",
    "    .groupby('index', as_index=False)\n",
    "    .apply(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "    .set_index('index')\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "# Balance sheets\n",
    "total_bs_df = pd.concat(bs_df_list).sort_index().reset_index()\n",
    "total_bs_df = (\n",
    "    total_bs_df\n",
    "    .groupby('index', as_index=False)\n",
    "    .apply(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "    .set_index('index')\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "# Cash flows\n",
    "total_cf_df = pd.concat(cf_df_list).sort_index().reset_index()\n",
    "total_cf_df = (\n",
    "    total_cf_df\n",
    "    .groupby('index', as_index=False)\n",
    "    .apply(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "    .set_index('index')\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "# Merge all data\n",
    "fundamental_df = pd.concat([total_is_df, total_bs_df, total_cf_df], axis=1)\n",
    "\n",
    "# Drop empty rows\n",
    "fundamental_df = fundamental_df.dropna(axis=0, how='all')\n",
    "\n",
    "# Drop empty columns\n",
    "threshold = int(len(fundamental_df) * 0.9) \n",
    "fundamental_df = fundamental_df.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "# Drop duplicate columns\n",
    "fundamental_df = fundamental_df.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mapping from long explanation to simple name\n",
    "fundamental_data_mapping_dict = dict()\n",
    "is_count = 1\n",
    "bs_count = 1\n",
    "cf_count = 1\n",
    "\n",
    "for col in fundamental_df.columns:\n",
    "    if col in total_is_df.columns:\n",
    "        fundamental_data_mapping_dict[col] = f'is_{is_count}'\n",
    "        is_count += 1\n",
    "    elif col in total_bs_df.columns:\n",
    "        fundamental_data_mapping_dict[col] = f'bs_{bs_count}'\n",
    "        bs_count += 1\n",
    "    elif col in total_cf_df.columns:\n",
    "        fundamental_data_mapping_dict[col] = f'cf_{cf_count}'\n",
    "        cf_count += 1\n",
    "    else:\n",
    "        raise Exception('Column not found in base data')\n",
    "\n",
    "# Rename columns\n",
    "fundamental_df = fundamental_df.rename(columns=fundamental_data_mapping_dict)\n",
    "\n",
    "# Save results in parquet format to avoid re-running process\n",
    "fundamental_df.to_parquet('data/fundamental_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save mapping dict\n",
    "with open('data/fundamental_variable_mapping.json', 'w') as fp:\n",
    "    json.dump(fundamental_data_mapping_dict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
